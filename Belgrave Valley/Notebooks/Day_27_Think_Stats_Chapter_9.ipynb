{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJzDT80B1MCe"
   },
   "source": [
    "<img src=\"https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_300,w_300,f_auto,q_auto/1266110/Logo_wzxi0f.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "**In my experience, it is rarer to find a really happy person in a circle of millionaires than among vagabonds - [Thor Heyerdahl](https://en.wikipedia.org/wiki/Thor_Heyerdahl)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "id": "zj9mCG8q1MCh"
   },
   "source": [
    "# Chapter 9 - Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "2EbPzfoU1MCi"
   },
   "source": [
    "## Classical hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "n_fmA61g1MCj"
   },
   "source": [
    "Exploring the data from the NSFG, we saw several “apparent effects,” including differences between first babies and others. So far we have taken these effects at face value; in this chapter, we put them to the test.\n",
    "\n",
    "The fundamental question we want to address is whether the effects we see in a sample are likely to appear in the larger population. For example, in the NSFG sample we see a difference in mean pregnancy length for first babies\n",
    "and others. We would like to know if that effect reflects a real difference for women in the U.S., or if it might appear in the sample by chance.\n",
    "\n",
    "There are several ways we could formulate this question, including Fisher null hypothesis testing, Neyman-Pearson decision theory, and Bayesian inference. What I present here is a subset of all three that makes up most of what people use in practice, which I will call **classical hypothesis testing**.\n",
    "\n",
    "The goal of classical hypothesis testing is to answer the question, “Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?” Here’s how we answer that question:\n",
    "\n",
    "1. The first step is to quantify the size of the apparent effect by choosing a **test statistic**. In the NSFG example, the apparent effect is a difference in pregnancy length between first babies and others, so a natural choice for the test statistic is the difference in means between the two groups.\n",
    "\n",
    "2. The second step is to define a **null hypothesis**, which is a model of the system based on the assumption that the apparent effect is not real. In the NSFG example the null hypothesis is that there is no difference between first babies and others; that is, that pregnancy lengths for both groups have the same distribution.\n",
    "\n",
    "3. The third step is to compute a **p-value**, which is the probability of seeing the apparent effect if the null hypothesis is true. In the NSFG example, we would compute the actual difference in means, then compute the probability of seeing a difference as big, or bigger, under the null hypothesis.\n",
    "\n",
    "4. The last step is to interpret the result. If the p-value is low, the effect is said to be **statistically significant**, which means that it is unlikely to have occurred by chance. In that case we infer that the effect is more likely to appear in the larger population.\n",
    "\n",
    "**Create a cram card asking the hypothesis testing process**\n",
    "\n",
    "The logic of this process is similar to a proof by contradiction. To prove a mathematical statement, A, you assume temporarily that A is false. If that assumption leads to a contradiction, you conclude that A must actually be\n",
    "true.\n",
    "\n",
    "Similarly, to test a hypothesis like, “This effect is real,” we assume, temporarily, that it is not. That’s the null hypothesis. Based on that assumption, we compute the probability of the apparent effect. That’s the p-value. If the p-value is low, we conclude that the null hypothesis is unlikely to be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "n_hYatqV1MCk"
   },
   "source": [
    "## Hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Jciod1HY1MCl"
   },
   "source": [
    "`thinkstats2` provides `HypothesisTest`, a class that represents the structure of a classical hypothesis test. Search it an copy it here and explain each of the parts of this parent class (read the following [blog](https://www.digitalocean.com/community/tutorials/understanding-class-inheritance-in-python-3)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "65C-r4kX1MCm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "CQxUd44C1MCq"
   },
   "source": [
    "`HypothesisTest` is an abstract parent class that provides complete definitions for some methods and place-keepers for others. Child classes based on `HypothesisTest` inherit `__init__` and `PValue` and provide `TestStatistic`, `RunModel`, and optionally `MakeModel`.\n",
    "\n",
    "`__init__` takes the data in whatever form is appropriate. It calls `MakeModel`, which builds a representation of the null hypothesis, then passes the data to `TestStatistic`, which computes the size of the effect in the sample.\n",
    "\n",
    "`PValue` computes the probability of the apparent effect under the null hypothesis. It takes as a parameter iters, which is the number of simulations to run. The first line generates simulated data, computes test statistics, and stores them in `test_stats`. The result is the fraction of elements in test_stats that exceed or equal the observed test statistic, `self.actual`.\n",
    "\n",
    "An example. Suppose we toss a coin 250 times and see 140 heads and 110 tails. Based on this result, we might suspect that the coin is biased; that is, more likely to land heads. To test this hypothesis, we compute the probability of seeing such a difference if the coin is actually fair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "13Q745DZ5sfa"
   },
   "outputs": [],
   "source": [
    "from Resources.Think_Stats.Thinkstats2 import thinkstats2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin():\n",
    "    results = []\n",
    "    for x in range(250):\n",
    "        '''we the experiment with a confidence level of 95%'''\n",
    "        '''sum of heads = test statistic'''\n",
    "        results.append(int(random.choice('10')))\n",
    "    '''sampling distribution'''\n",
    "    return sum(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue  2.7 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Since the Pvalue is under 5% there is a statistical significance, so the coin is biased'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for _ in list(range(1000)):\n",
    "    result.append(coin())\n",
    "\n",
    "'''null hypothesis = having a fair coin'''    \n",
    "\n",
    "mayores = 0\n",
    "for x in result:\n",
    "    if x>= 140:\n",
    "        mayores += 1\n",
    "print('pvalue ', mayores/len(result)*100,'%')\n",
    "\n",
    "\n",
    "'''The Pvalue is the probability of getting a result as extreme or more than the one we observed under the\n",
    "null hypothesis'''\n",
    "'''Since the Pvalue is under 5% there is a statistical significance, so the coin is biased'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.707"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(coin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_m():\n",
    "    results = []\n",
    "    for x in range(250):\n",
    "        '''we the experiment with a confidence level of 95%'''\n",
    "        '''sum of heads = test statistic'''\n",
    "        results.append(int(random.choice('10')))\n",
    "    '''sampling distribution'''\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue  3.3000000000000003 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Pvalue is the probability of getting a result as extreme or more than the one we observed under the\\nnull hypothesis. \\n Since the Pvalue is under 5% there is a statistical significance, so the coin is biased'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_m = []\n",
    "for _ in list(range(1000)):\n",
    "    result_m.append(coin_m())\n",
    "\n",
    "'''null hypothesis = having a fair coin'''    \n",
    "\n",
    "mayores_m = 0\n",
    "for x in result_m:\n",
    "    if x>= 140/250:\n",
    "        mayores_m += 1\n",
    "print('pvalue ', mayores_m/len(result_m)*100,'%')\n",
    "\n",
    "\n",
    "'''The Pvalue is the probability of getting a result as extreme or more than the one we observed under the\n",
    "null hypothesis. \\n Since the Pvalue is under 5% there is a statistical significance, so the coin is biased'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "400 veces 40 cincos\n",
    "1. Test Statistic = sum de 5s\n",
    "2. Null Hypothesis\n",
    "3. Pvalue\n",
    "4. Statistically Significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_5():\n",
    "    results = []\n",
    "    for x in range(400):\n",
    "        '''we the experiment with a confidence level of 95%'''\n",
    "        '''sum of 5s = test statistic'''\n",
    "        results.append(int(random.choice('000005')))\n",
    "    '''sampling distribution'''\n",
    "    return sum(results)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66.0,\n",
       " 59.0,\n",
       " 70.0,\n",
       " 68.0,\n",
       " 67.0,\n",
       " 67.0,\n",
       " 60.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 62.0,\n",
       " 71.0,\n",
       " 59.0,\n",
       " 57.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 79.0,\n",
       " 68.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 66.0,\n",
       " 79.0,\n",
       " 66.0,\n",
       " 65.0,\n",
       " 60.0,\n",
       " 72.0,\n",
       " 59.0,\n",
       " 70.0,\n",
       " 62.0,\n",
       " 82.0,\n",
       " 83.0,\n",
       " 72.0,\n",
       " 58.0,\n",
       " 79.0,\n",
       " 64.0,\n",
       " 60.0,\n",
       " 68.0,\n",
       " 65.0,\n",
       " 78.0,\n",
       " 68.0,\n",
       " 72.0,\n",
       " 61.0,\n",
       " 75.0,\n",
       " 58.0,\n",
       " 54.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 62.0,\n",
       " 69.0,\n",
       " 67.0,\n",
       " 80.0,\n",
       " 67.0,\n",
       " 62.0,\n",
       " 63.0,\n",
       " 71.0,\n",
       " 76.0,\n",
       " 67.0,\n",
       " 76.0,\n",
       " 78.0,\n",
       " 72.0,\n",
       " 61.0,\n",
       " 52.0,\n",
       " 76.0,\n",
       " 58.0,\n",
       " 62.0,\n",
       " 73.0,\n",
       " 74.0,\n",
       " 64.0,\n",
       " 60.0,\n",
       " 49.0,\n",
       " 62.0,\n",
       " 65.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 51.0,\n",
       " 70.0,\n",
       " 67.0,\n",
       " 75.0,\n",
       " 58.0,\n",
       " 64.0,\n",
       " 72.0,\n",
       " 66.0,\n",
       " 64.0,\n",
       " 63.0,\n",
       " 65.0,\n",
       " 58.0,\n",
       " 81.0,\n",
       " 82.0,\n",
       " 58.0,\n",
       " 69.0,\n",
       " 85.0,\n",
       " 66.0,\n",
       " 61.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 59.0,\n",
       " 62.0,\n",
       " 58.0,\n",
       " 63.0,\n",
       " 69.0,\n",
       " 61.0,\n",
       " 79.0,\n",
       " 70.0,\n",
       " 68.0,\n",
       " 64.0,\n",
       " 70.0,\n",
       " 68.0,\n",
       " 76.0,\n",
       " 75.0,\n",
       " 65.0,\n",
       " 73.0,\n",
       " 74.0,\n",
       " 64.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 76.0,\n",
       " 94.0,\n",
       " 72.0,\n",
       " 72.0,\n",
       " 62.0,\n",
       " 48.0,\n",
       " 75.0,\n",
       " 77.0,\n",
       " 71.0,\n",
       " 60.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 59.0,\n",
       " 78.0,\n",
       " 81.0,\n",
       " 84.0,\n",
       " 74.0,\n",
       " 81.0,\n",
       " 76.0,\n",
       " 72.0,\n",
       " 64.0,\n",
       " 60.0,\n",
       " 71.0,\n",
       " 79.0,\n",
       " 69.0,\n",
       " 55.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 67.0,\n",
       " 63.0,\n",
       " 69.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 61.0,\n",
       " 71.0,\n",
       " 75.0,\n",
       " 78.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 68.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 58.0,\n",
       " 69.0,\n",
       " 77.0,\n",
       " 70.0,\n",
       " 79.0,\n",
       " 53.0,\n",
       " 71.0,\n",
       " 65.0,\n",
       " 73.0,\n",
       " 63.0,\n",
       " 70.0,\n",
       " 69.0,\n",
       " 75.0,\n",
       " 79.0,\n",
       " 67.0,\n",
       " 65.0,\n",
       " 74.0,\n",
       " 77.0,\n",
       " 62.0,\n",
       " 65.0,\n",
       " 70.0,\n",
       " 78.0,\n",
       " 67.0,\n",
       " 71.0,\n",
       " 65.0,\n",
       " 52.0,\n",
       " 72.0,\n",
       " 73.0,\n",
       " 74.0,\n",
       " 59.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 65.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 53.0,\n",
       " 64.0,\n",
       " 61.0,\n",
       " 71.0,\n",
       " 76.0,\n",
       " 71.0,\n",
       " 67.0,\n",
       " 57.0,\n",
       " 74.0,\n",
       " 64.0,\n",
       " 72.0,\n",
       " 71.0,\n",
       " 59.0,\n",
       " 72.0,\n",
       " 61.0,\n",
       " 76.0,\n",
       " 74.0,\n",
       " 57.0,\n",
       " 63.0,\n",
       " 51.0,\n",
       " 68.0,\n",
       " 60.0,\n",
       " 74.0,\n",
       " 62.0,\n",
       " 54.0,\n",
       " 75.0,\n",
       " 66.0,\n",
       " 60.0,\n",
       " 74.0,\n",
       " 74.0,\n",
       " 63.0,\n",
       " 70.0,\n",
       " 64.0,\n",
       " 56.0,\n",
       " 79.0,\n",
       " 63.0,\n",
       " 73.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 67.0,\n",
       " 73.0,\n",
       " 58.0,\n",
       " 75.0,\n",
       " 59.0,\n",
       " 70.0,\n",
       " 62.0,\n",
       " 61.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 56.0,\n",
       " 55.0,\n",
       " 71.0,\n",
       " 82.0,\n",
       " 60.0,\n",
       " 68.0,\n",
       " 64.0,\n",
       " 59.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 61.0,\n",
       " 64.0,\n",
       " 59.0,\n",
       " 60.0,\n",
       " 70.0,\n",
       " 56.0,\n",
       " 77.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 63.0,\n",
       " 73.0,\n",
       " 61.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 66.0,\n",
       " 87.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 59.0,\n",
       " 66.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 63.0,\n",
       " 68.0,\n",
       " 59.0,\n",
       " 78.0,\n",
       " 73.0,\n",
       " 67.0,\n",
       " 46.0,\n",
       " 67.0,\n",
       " 74.0,\n",
       " 72.0,\n",
       " 70.0,\n",
       " 64.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 62.0,\n",
       " 58.0,\n",
       " 65.0,\n",
       " 69.0,\n",
       " 57.0,\n",
       " 64.0,\n",
       " 64.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 68.0,\n",
       " 71.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 45.0,\n",
       " 60.0,\n",
       " 64.0,\n",
       " 68.0,\n",
       " 67.0,\n",
       " 72.0,\n",
       " 81.0,\n",
       " 54.0,\n",
       " 66.0,\n",
       " 58.0,\n",
       " 66.0,\n",
       " 63.0,\n",
       " 67.0,\n",
       " 50.0,\n",
       " 65.0,\n",
       " 73.0,\n",
       " 78.0,\n",
       " 62.0,\n",
       " 67.0,\n",
       " 70.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 65.0,\n",
       " 70.0,\n",
       " 53.0,\n",
       " 55.0,\n",
       " 53.0,\n",
       " 81.0,\n",
       " 71.0,\n",
       " 62.0,\n",
       " 72.0,\n",
       " 71.0,\n",
       " 69.0,\n",
       " 66.0,\n",
       " 71.0,\n",
       " 75.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 70.0,\n",
       " 67.0,\n",
       " 61.0,\n",
       " 59.0,\n",
       " 72.0,\n",
       " 66.0,\n",
       " 56.0,\n",
       " 70.0,\n",
       " 73.0,\n",
       " 75.0,\n",
       " 77.0,\n",
       " 51.0,\n",
       " 71.0,\n",
       " 59.0,\n",
       " 81.0,\n",
       " 63.0,\n",
       " 74.0,\n",
       " 75.0,\n",
       " 71.0,\n",
       " 66.0,\n",
       " 60.0,\n",
       " 67.0,\n",
       " 61.0,\n",
       " 67.0,\n",
       " 59.0,\n",
       " 71.0,\n",
       " 58.0,\n",
       " 57.0,\n",
       " 67.0,\n",
       " 62.0,\n",
       " 71.0,\n",
       " 75.0,\n",
       " 56.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 56.0,\n",
       " 74.0,\n",
       " 60.0,\n",
       " 64.0,\n",
       " 63.0,\n",
       " 60.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 75.0,\n",
       " 79.0,\n",
       " 61.0,\n",
       " 58.0,\n",
       " 67.0,\n",
       " 61.0,\n",
       " 76.0,\n",
       " 54.0,\n",
       " 65.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 58.0,\n",
       " 68.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 84.0,\n",
       " 64.0,\n",
       " 63.0,\n",
       " 69.0,\n",
       " 64.0,\n",
       " 71.0,\n",
       " 58.0,\n",
       " 83.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 67.0,\n",
       " 69.0,\n",
       " 67.0,\n",
       " 64.0,\n",
       " 67.0,\n",
       " 67.0,\n",
       " 68.0,\n",
       " 58.0,\n",
       " 60.0,\n",
       " 68.0,\n",
       " 63.0,\n",
       " 67.0,\n",
       " 74.0,\n",
       " 57.0,\n",
       " 67.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 59.0,\n",
       " 62.0,\n",
       " 72.0,\n",
       " 67.0,\n",
       " 65.0,\n",
       " 51.0,\n",
       " 74.0,\n",
       " 63.0,\n",
       " 58.0,\n",
       " 69.0,\n",
       " 71.0,\n",
       " 61.0,\n",
       " 56.0,\n",
       " 64.0,\n",
       " 66.0,\n",
       " 56.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 79.0,\n",
       " 57.0,\n",
       " 69.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 58.0,\n",
       " 59.0,\n",
       " 77.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 72.0,\n",
       " 67.0,\n",
       " 67.0,\n",
       " 65.0,\n",
       " 69.0,\n",
       " 51.0,\n",
       " 70.0,\n",
       " 74.0,\n",
       " 76.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 80.0,\n",
       " 60.0,\n",
       " 67.0,\n",
       " 65.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 70.0,\n",
       " 60.0,\n",
       " 72.0,\n",
       " 70.0,\n",
       " 61.0,\n",
       " 75.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 69.0,\n",
       " 66.0,\n",
       " 67.0,\n",
       " 76.0,\n",
       " 70.0,\n",
       " 62.0,\n",
       " 73.0,\n",
       " 62.0,\n",
       " 72.0,\n",
       " 64.0,\n",
       " 60.0,\n",
       " 55.0,\n",
       " 59.0,\n",
       " 65.0,\n",
       " 68.0,\n",
       " 67.0,\n",
       " 62.0,\n",
       " 79.0,\n",
       " 65.0,\n",
       " 58.0,\n",
       " 64.0,\n",
       " 73.0,\n",
       " 80.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 80.0,\n",
       " 70.0,\n",
       " 56.0,\n",
       " 67.0,\n",
       " 74.0,\n",
       " 77.0,\n",
       " 73.0,\n",
       " 69.0,\n",
       " 79.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 77.0,\n",
       " 64.0,\n",
       " 66.0,\n",
       " 69.0,\n",
       " 67.0,\n",
       " 64.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 62.0,\n",
       " 65.0,\n",
       " 60.0,\n",
       " 65.0,\n",
       " 69.0,\n",
       " 79.0,\n",
       " 63.0,\n",
       " 69.0,\n",
       " 71.0,\n",
       " 74.0,\n",
       " 76.0,\n",
       " 67.0,\n",
       " 58.0,\n",
       " 66.0,\n",
       " 54.0,\n",
       " 66.0,\n",
       " 69.0,\n",
       " 57.0,\n",
       " 63.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 69.0,\n",
       " 82.0,\n",
       " 60.0,\n",
       " 64.0,\n",
       " 63.0,\n",
       " 78.0,\n",
       " 50.0,\n",
       " 72.0,\n",
       " 62.0,\n",
       " 56.0,\n",
       " 86.0,\n",
       " 82.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 60.0,\n",
       " 64.0,\n",
       " 77.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 77.0,\n",
       " 72.0,\n",
       " 71.0,\n",
       " 68.0,\n",
       " 62.0,\n",
       " 67.0,\n",
       " 59.0,\n",
       " 62.0,\n",
       " 84.0,\n",
       " 63.0,\n",
       " 72.0,\n",
       " 69.0,\n",
       " 61.0,\n",
       " 47.0,\n",
       " 75.0,\n",
       " 70.0,\n",
       " 62.0,\n",
       " 62.0,\n",
       " 79.0,\n",
       " 72.0,\n",
       " 53.0,\n",
       " 72.0,\n",
       " 57.0,\n",
       " 58.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 70.0,\n",
       " 60.0,\n",
       " 65.0,\n",
       " 60.0,\n",
       " 62.0,\n",
       " 57.0,\n",
       " 76.0,\n",
       " 68.0,\n",
       " 66.0,\n",
       " 59.0,\n",
       " 70.0,\n",
       " 58.0,\n",
       " 68.0,\n",
       " 65.0,\n",
       " 72.0,\n",
       " 61.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 61.0,\n",
       " 68.0,\n",
       " 69.0,\n",
       " 71.0,\n",
       " 80.0,\n",
       " 85.0,\n",
       " 62.0,\n",
       " 56.0,\n",
       " 65.0,\n",
       " 74.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 61.0,\n",
       " 60.0,\n",
       " 65.0,\n",
       " 63.0,\n",
       " 57.0,\n",
       " 77.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 75.0,\n",
       " 67.0,\n",
       " 59.0,\n",
       " 69.0,\n",
       " 75.0,\n",
       " 60.0,\n",
       " 58.0,\n",
       " 51.0,\n",
       " 69.0,\n",
       " 60.0,\n",
       " 73.0,\n",
       " 60.0,\n",
       " 73.0,\n",
       " 57.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 52.0,\n",
       " 71.0,\n",
       " 74.0,\n",
       " 61.0,\n",
       " 65.0,\n",
       " 74.0,\n",
       " 53.0,\n",
       " 61.0,\n",
       " 76.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 70.0,\n",
       " 51.0,\n",
       " 64.0,\n",
       " 79.0,\n",
       " 71.0,\n",
       " 64.0,\n",
       " 70.0,\n",
       " 74.0,\n",
       " 61.0,\n",
       " 68.0,\n",
       " 66.0,\n",
       " 64.0,\n",
       " 63.0,\n",
       " 54.0,\n",
       " 50.0,\n",
       " 73.0,\n",
       " 73.0,\n",
       " 69.0,\n",
       " 64.0,\n",
       " 73.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 49.0,\n",
       " 74.0,\n",
       " 70.0,\n",
       " 78.0,\n",
       " 63.0,\n",
       " 68.0,\n",
       " 71.0,\n",
       " 70.0,\n",
       " 61.0,\n",
       " 57.0,\n",
       " 70.0,\n",
       " 80.0,\n",
       " 77.0,\n",
       " 71.0,\n",
       " 58.0,\n",
       " 59.0,\n",
       " 68.0,\n",
       " 80.0,\n",
       " 61.0,\n",
       " 64.0,\n",
       " 80.0,\n",
       " 56.0,\n",
       " 66.0,\n",
       " 55.0,\n",
       " 70.0,\n",
       " 66.0,\n",
       " 69.0,\n",
       " 68.0,\n",
       " 78.0,\n",
       " 61.0,\n",
       " 69.0,\n",
       " 71.0,\n",
       " 60.0,\n",
       " 54.0,\n",
       " 64.0,\n",
       " 75.0,\n",
       " 66.0,\n",
       " 64.0,\n",
       " 66.0,\n",
       " 57.0,\n",
       " 67.0,\n",
       " 64.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 68.0,\n",
       " 73.0,\n",
       " 68.0,\n",
       " 69.0,\n",
       " 56.0,\n",
       " 63.0,\n",
       " 58.0,\n",
       " 70.0,\n",
       " 58.0,\n",
       " 57.0,\n",
       " 73.0,\n",
       " 55.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 61.0,\n",
       " 70.0,\n",
       " 72.0,\n",
       " 70.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 74.0,\n",
       " 74.0,\n",
       " 62.0,\n",
       " 61.0,\n",
       " 53.0,\n",
       " 78.0,\n",
       " 60.0,\n",
       " 53.0,\n",
       " 57.0,\n",
       " 73.0,\n",
       " 65.0,\n",
       " 61.0,\n",
       " 81.0,\n",
       " 54.0,\n",
       " 68.0,\n",
       " 74.0,\n",
       " 67.0,\n",
       " 63.0,\n",
       " 81.0,\n",
       " 66.0,\n",
       " 53.0,\n",
       " 74.0,\n",
       " 78.0,\n",
       " 75.0,\n",
       " 71.0,\n",
       " 57.0,\n",
       " 68.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 61.0,\n",
       " 60.0,\n",
       " 66.0,\n",
       " 65.0,\n",
       " 67.0,\n",
       " 55.0,\n",
       " 61.0,\n",
       " 57.0,\n",
       " 66.0,\n",
       " 90.0,\n",
       " 72.0,\n",
       " 69.0,\n",
       " 54.0,\n",
       " 69.0,\n",
       " 67.0,\n",
       " 70.0,\n",
       " 87.0,\n",
       " 61.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 56.0,\n",
       " 68.0,\n",
       " 72.0,\n",
       " 62.0,\n",
       " 61.0,\n",
       " 55.0,\n",
       " 78.0,\n",
       " 64.0,\n",
       " 71.0,\n",
       " 65.0,\n",
       " 71.0,\n",
       " 59.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 64.0,\n",
       " 68.0,\n",
       " 62.0,\n",
       " 68.0,\n",
       " 63.0,\n",
       " 64.0,\n",
       " 62.0,\n",
       " 70.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 79.0,\n",
       " 58.0,\n",
       " 55.0,\n",
       " 60.0,\n",
       " 75.0,\n",
       " 52.0,\n",
       " 55.0,\n",
       " 72.0,\n",
       " 63.0,\n",
       " 69.0,\n",
       " 76.0,\n",
       " 62.0,\n",
       " 67.0,\n",
       " 70.0,\n",
       " 76.0,\n",
       " 65.0,\n",
       " 50.0,\n",
       " 69.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 87.0,\n",
       " 61.0,\n",
       " 80.0,\n",
       " 69.0,\n",
       " 56.0,\n",
       " 56.0,\n",
       " 75.0,\n",
       " 60.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 62.0,\n",
       " 61.0,\n",
       " 66.0,\n",
       " 64.0,\n",
       " 74.0,\n",
       " 73.0,\n",
       " 71.0,\n",
       " 69.0,\n",
       " 83.0,\n",
       " 69.0,\n",
       " 72.0,\n",
       " 67.0,\n",
       " 56.0,\n",
       " 61.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 62.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 66.0,\n",
       " 63.0,\n",
       " 58.0,\n",
       " 82.0,\n",
       " 64.0,\n",
       " 66.0,\n",
       " 72.0,\n",
       " 65.0,\n",
       " 70.0,\n",
       " 60.0,\n",
       " 77.0,\n",
       " 54.0,\n",
       " 76.0,\n",
       " 69.0,\n",
       " 61.0,\n",
       " 67.0,\n",
       " 69.0,\n",
       " 77.0,\n",
       " 61.0,\n",
       " 84.0,\n",
       " 72.0,\n",
       " 68.0,\n",
       " 64.0,\n",
       " 58.0,\n",
       " 67.0,\n",
       " 69.0,\n",
       " 63.0,\n",
       " 60.0,\n",
       " 57.0,\n",
       " 64.0,\n",
       " 54.0,\n",
       " 80.0,\n",
       " 59.0,\n",
       " 69.0,\n",
       " 74.0,\n",
       " 69.0,\n",
       " 54.0,\n",
       " 63.0,\n",
       " 82.0,\n",
       " 68.0,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 69.0,\n",
       " 58.0,\n",
       " 63.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 46.0,\n",
       " 73.0,\n",
       " 67.0,\n",
       " 66.0,\n",
       " 65.0,\n",
       " 64.0,\n",
       " 67.0,\n",
       " 68.0,\n",
       " 62.0,\n",
       " 59.0,\n",
       " 71.0,\n",
       " 67.0,\n",
       " 72.0,\n",
       " 59.0,\n",
       " 64.0,\n",
       " 75.0,\n",
       " 65.0,\n",
       " 54.0,\n",
       " 64.0,\n",
       " 54.0,\n",
       " 69.0,\n",
       " 60.0,\n",
       " 56.0,\n",
       " 72.0,\n",
       " 67.0,\n",
       " 72.0,\n",
       " 86.0,\n",
       " 82.0,\n",
       " 62.0,\n",
       " 65.0,\n",
       " 55.0,\n",
       " 72.0,\n",
       " 61.0,\n",
       " 61.0,\n",
       " 68.0,\n",
       " 74.0,\n",
       " 77.0,\n",
       " 64.0,\n",
       " 57.0,\n",
       " 72.0,\n",
       " 60.0,\n",
       " 63.0,\n",
       " 61.0,\n",
       " 56.0,\n",
       " 74.0,\n",
       " 79.0,\n",
       " 63.0,\n",
       " 78.0,\n",
       " 73.0,\n",
       " 72.0,\n",
       " 71.0,\n",
       " 55.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 76.0,\n",
       " 65.0,\n",
       " 57.0,\n",
       " 81.0,\n",
       " 59.0,\n",
       " 79.0,\n",
       " 80.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 72.0,\n",
       " 75.0,\n",
       " 73.0,\n",
       " 76.0,\n",
       " 69.0,\n",
       " 79.0,\n",
       " 57.0,\n",
       " 63.0,\n",
       " 67.0,\n",
       " 69.0,\n",
       " 70.0,\n",
       " 48.0]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_d = []\n",
    "for _ in list(range(1000)):\n",
    "    result_d.append(dice_5())\n",
    "\n",
    "'''null hypothesis = having a fair dice'''    \n",
    "result_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue  0.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Pvalue is under 5% meaning it is statistically significant. We ran the experiment 1000 times under the null\\nhypothesis and we never got as few as 40 5s. The minimum was 45. The dice IS BIASED'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Calculating Pvalue'''\n",
    "cincos = 0\n",
    "for x in result_d:\n",
    "    if x<=40:\n",
    "        cincos += 1\n",
    "print('pvalue ', cincos/len(result_d)*100,'%')\n",
    "'''The Pvalue is under 5% meaning it is statistically significant. We ran the experiment 1000 times under the null\n",
    "hypothesis and we never got as few as 40 5s. The minimum was 45. The dice IS BIASED''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "AsG6VVqu1MCr"
   },
   "outputs": [],
   "source": [
    "class CoinTest(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        heads, tails = data\n",
    "        test_stat = abs(heads - tails)\n",
    "        return test_stat\n",
    "    \n",
    "    def RunModel(self):\n",
    "        heads, tails = self.data\n",
    "        n = heads + tails\n",
    "        sample = [random.choice('HT') for _ in range(n)]\n",
    "        hist = thinkstats2.Hist(sample)\n",
    "        data = hist['H'], hist['T']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "kBvp1i1F1MCu"
   },
   "source": [
    "The parameter, `data`, is a pair of integers: the number of heads and tails. The test statistic is the absolute difference between them, so `self.actual`\n",
    "is 30.\n",
    "\n",
    "`RunModel` simulates coin tosses assuming that the coin is actually fair. It generates a sample of 250 tosses, uses `Hist` to count the number of heads and tails, and returns a pair of integers.\n",
    "\n",
    "Now all we have to do is instantiate `CoinTest` and call `PValue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "jUJbsavI1MCv"
   },
   "outputs": [],
   "source": [
    "ct = CoinTest((140, 110))\n",
    "pvalue = ct.PValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "COEUUwwi1MCz",
    "outputId": "b51ea6fc-028a-43e6-9d8f-d6be2ac002f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.066"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "aVX5JbdE1MC3"
   },
   "source": [
    "The result is about 0.07, which means that if the coin is fair, we expect to see a difference as big as 30 about 7% of the time.\n",
    "\n",
    "How should we interpret this result? By convention, 5% is the threshold of statistical significance. If the p-value is less than 5%, the effect is considered significant; otherwise it is not.\n",
    "\n",
    "But the choice of 5% is arbitrary, and (as we will see later) the p-value depends on the choice of the test statistics and the model of the null hypothesis. So p-values should not be considered precise measurements.\n",
    "\n",
    "I recommend interpreting p-values according to their order of magnitude: if the p-value is less than 1%, the effect is unlikely to be due to chance; if it is greater than 10%, the effect can plausibly be explained by chance. P-values between 1% and 10% should be considered borderline. So in this example I conclude that the data do not provide strong evidence that the coin is biased or not.\n",
    "\n",
    "Create a new experiment. Suppose we roll a dice 400 times and see 40 fives. Based on this result, we might suspect that the dice is biased; that is, more less likely to get a 5. To test this hypothesis, compute the probability of seeing such a difference if the dice is actually fair.\n",
    "\n",
    "Create a test to calculate it and call `PValue`. To do so create your own class that uses `thinkstats2.HypothesisTest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Aiaa2-fT1MC4"
   },
   "outputs": [],
   "source": [
    "class DiceTest(thinkstats2.HypothesisTest):\n",
    "    \n",
    "     def TestStatistic(self, data):\n",
    "        five, not_five = data\n",
    "        test_stat = five\n",
    "        return test_stat\n",
    "    \n",
    "     def RunModel(self):\n",
    "        five, not_five = self.data\n",
    "        n = five + not_five\n",
    "        sample = [random.choice('111115') for _ in range(n)]\n",
    "        hist = thinkstats2.Hist(sample)\n",
    "        data = hist['5'], hist['1']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DiceTest((40, 360))\n",
    "pvalue = dt.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "ZN1ypTTb1MC_"
   },
   "source": [
    "## Testing a difference in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "r552DPvh1MDA"
   },
   "source": [
    "One of the most common effects to test is a difference in mean between two groups. In the NSFG data, we saw that the mean pregnancy length for first babies is slightly longer, and the mean birth weight is slightly smaller. Now we will see if those effects are statistically significant.\n",
    "\n",
    "For these examples, the null hypothesis is that the distributions for the two groups are the same. One way to model the null hypothesis is by **permutation**; that is, we can take values for first babies and others and shuffle them, treating the two groups as one big group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "7dvfqC1OFc7e"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "FsVCnjy71MDB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thinkstats2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x5/c_gzdbcx3cq5rrz54srqf47c0000gn/T/ipykernel_72304/310849370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDiffMeansPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthinkstats2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHypothesisTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTestStatistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgroup1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgroup2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'thinkstats2' is not defined"
     ]
    }
   ],
   "source": [
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "    \n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "        \n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resources.Think_Stats.Thinkstats2 import first\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "0mqtobfZ1MDE"
   },
   "source": [
    "`data` is a pair of sequences, one for each group. The test statistic is the absolute difference in the means.\n",
    "\n",
    "`MakeModel` records the sizes of the groups, n and m, and combines the groups into one NumPy array, `self.pool`.\n",
    "\n",
    "`RunModel` simulates the null hypothesis by shuffling the pooled values and splitting them into two groups with sizes n and m. As always, the return value from `RunModel` has the same format as the observed data.\n",
    "\n",
    "To test the difference in pregnancy length, we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "3B2SQzEpINh4"
   },
   "outputs": [],
   "source": [
    "from Resources.Think_Stats.Thinkstats2 import first\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "FvzMVwYx1MDM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DiffMeansPermute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x5/c_gzdbcx3cq5rrz54srqf47c0000gn/T/ipykernel_72304/291322990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeFrames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirsts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprglngth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprglngth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffMeansPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DiffMeansPermute' is not defined"
     ]
    }
   ],
   "source": [
    "live, firsts, others = first.MakeFrames()\n",
    "data = firsts.prglngth.values, others.prglngth.values\n",
    "ht = DiffMeansPermute(data)\n",
    "pvalue = ht.PValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>pregordr</th>\n",
       "      <th>howpreg_n</th>\n",
       "      <th>howpreg_p</th>\n",
       "      <th>moscurrp</th>\n",
       "      <th>nowprgdk</th>\n",
       "      <th>pregend1</th>\n",
       "      <th>pregend2</th>\n",
       "      <th>nbrnaliv</th>\n",
       "      <th>multbrth</th>\n",
       "      <th>cmotpreg</th>\n",
       "      <th>prgoutcome</th>\n",
       "      <th>cmprgend</th>\n",
       "      <th>flgdkmo1</th>\n",
       "      <th>cmprgbeg</th>\n",
       "      <th>ageatend</th>\n",
       "      <th>hpageend</th>\n",
       "      <th>gestasun_m</th>\n",
       "      <th>gestasun_w</th>\n",
       "      <th>wksgest</th>\n",
       "      <th>mosgest</th>\n",
       "      <th>dk1gest</th>\n",
       "      <th>dk2gest</th>\n",
       "      <th>dk3gest</th>\n",
       "      <th>bpa_bdscheck1</th>\n",
       "      <th>bpa_bdscheck2</th>\n",
       "      <th>bpa_bdscheck3</th>\n",
       "      <th>babysex</th>\n",
       "      <th>birthwgt_lb</th>\n",
       "      <th>birthwgt_oz</th>\n",
       "      <th>lobthwgt</th>\n",
       "      <th>babysex2</th>\n",
       "      <th>birthwgt_lb2</th>\n",
       "      <th>birthwgt_oz2</th>\n",
       "      <th>lobthwgt2</th>\n",
       "      <th>babysex3</th>\n",
       "      <th>birthwgt_lb3</th>\n",
       "      <th>birthwgt_oz3</th>\n",
       "      <th>lobthwgt3</th>\n",
       "      <th>cmbabdob</th>\n",
       "      <th>kidage</th>\n",
       "      <th>hpagelb</th>\n",
       "      <th>birthplc</th>\n",
       "      <th>paybirth1</th>\n",
       "      <th>paybirth2</th>\n",
       "      <th>paybirth3</th>\n",
       "      <th>knewpreg</th>\n",
       "      <th>trimestr</th>\n",
       "      <th>ltrimest</th>\n",
       "      <th>priorsmk</th>\n",
       "      <th>postsmks</th>\n",
       "      <th>npostsmk</th>\n",
       "      <th>getprena</th>\n",
       "      <th>bgnprena</th>\n",
       "      <th>pnctrim</th>\n",
       "      <th>lpnctri</th>\n",
       "      <th>workpreg</th>\n",
       "      <th>workborn</th>\n",
       "      <th>didwork</th>\n",
       "      <th>matweeks</th>\n",
       "      <th>weeksdk</th>\n",
       "      <th>matleave</th>\n",
       "      <th>matchfound</th>\n",
       "      <th>livehere</th>\n",
       "      <th>alivenow</th>\n",
       "      <th>cmkidied</th>\n",
       "      <th>cmkidlft</th>\n",
       "      <th>lastage</th>\n",
       "      <th>wherenow</th>\n",
       "      <th>legagree</th>\n",
       "      <th>parenend</th>\n",
       "      <th>anynurse</th>\n",
       "      <th>fedsolid</th>\n",
       "      <th>frsteatd_n</th>\n",
       "      <th>frsteatd_p</th>\n",
       "      <th>frsteatd</th>\n",
       "      <th>quitnurs</th>\n",
       "      <th>ageqtnur_n</th>\n",
       "      <th>ageqtnur_p</th>\n",
       "      <th>ageqtnur</th>\n",
       "      <th>matchfound2</th>\n",
       "      <th>livehere2</th>\n",
       "      <th>alivenow2</th>\n",
       "      <th>cmkidied2</th>\n",
       "      <th>cmkidlft2</th>\n",
       "      <th>lastage2</th>\n",
       "      <th>wherenow2</th>\n",
       "      <th>legagree2</th>\n",
       "      <th>parenend2</th>\n",
       "      <th>anynurse2</th>\n",
       "      <th>fedsolid2</th>\n",
       "      <th>frsteatd_n2</th>\n",
       "      <th>frsteatd_p2</th>\n",
       "      <th>frsteatd2</th>\n",
       "      <th>quitnurs2</th>\n",
       "      <th>ageqtnur_n2</th>\n",
       "      <th>ageqtnur_p2</th>\n",
       "      <th>ageqtnur2</th>\n",
       "      <th>matchfound3</th>\n",
       "      <th>livehere3</th>\n",
       "      <th>alivenow3</th>\n",
       "      <th>cmkidied3</th>\n",
       "      <th>cmkidlft3</th>\n",
       "      <th>lastage3</th>\n",
       "      <th>wherenow3</th>\n",
       "      <th>legagree3</th>\n",
       "      <th>parenend3</th>\n",
       "      <th>anynurse3</th>\n",
       "      <th>fedsolid3</th>\n",
       "      <th>frsteatd_n3</th>\n",
       "      <th>frsteatd_p3</th>\n",
       "      <th>frsteatd3</th>\n",
       "      <th>quitnurs3</th>\n",
       "      <th>ageqtnur_n3</th>\n",
       "      <th>ageqtnur_p3</th>\n",
       "      <th>ageqtnur3</th>\n",
       "      <th>cmlastlb</th>\n",
       "      <th>cmfstprg</th>\n",
       "      <th>cmlstprg</th>\n",
       "      <th>cmintstr</th>\n",
       "      <th>cmintfin</th>\n",
       "      <th>cmintstrop</th>\n",
       "      <th>cmintfinop</th>\n",
       "      <th>cmintstrcr</th>\n",
       "      <th>cmintfincr</th>\n",
       "      <th>evuseint</th>\n",
       "      <th>stopduse</th>\n",
       "      <th>whystopd</th>\n",
       "      <th>whatmeth01</th>\n",
       "      <th>whatmeth02</th>\n",
       "      <th>whatmeth03</th>\n",
       "      <th>whatmeth04</th>\n",
       "      <th>resnouse</th>\n",
       "      <th>wantbold</th>\n",
       "      <th>probbabe</th>\n",
       "      <th>cnfrmno</th>\n",
       "      <th>wantbld2</th>\n",
       "      <th>timingok</th>\n",
       "      <th>toosoon_n</th>\n",
       "      <th>toosoon_p</th>\n",
       "      <th>wthpart1</th>\n",
       "      <th>wthpart2</th>\n",
       "      <th>feelinpg</th>\n",
       "      <th>hpwnold</th>\n",
       "      <th>timokhp</th>\n",
       "      <th>cohpbeg</th>\n",
       "      <th>cohpend</th>\n",
       "      <th>tellfath</th>\n",
       "      <th>whentell</th>\n",
       "      <th>tryscale</th>\n",
       "      <th>wantscal</th>\n",
       "      <th>whyprg1</th>\n",
       "      <th>whyprg2</th>\n",
       "      <th>whynouse1</th>\n",
       "      <th>whynouse2</th>\n",
       "      <th>whynouse3</th>\n",
       "      <th>anyusint</th>\n",
       "      <th>prglngth</th>\n",
       "      <th>outcome</th>\n",
       "      <th>birthord</th>\n",
       "      <th>datend</th>\n",
       "      <th>agepreg</th>\n",
       "      <th>datecon</th>\n",
       "      <th>agecon</th>\n",
       "      <th>fmarout5</th>\n",
       "      <th>pmarpreg</th>\n",
       "      <th>rmarout6</th>\n",
       "      <th>fmarcon5</th>\n",
       "      <th>learnprg</th>\n",
       "      <th>pncarewk</th>\n",
       "      <th>paydeliv</th>\n",
       "      <th>lbw1</th>\n",
       "      <th>bfeedwks</th>\n",
       "      <th>maternlv</th>\n",
       "      <th>oldwantr</th>\n",
       "      <th>oldwantp</th>\n",
       "      <th>wantresp</th>\n",
       "      <th>wantpart</th>\n",
       "      <th>cmbirth</th>\n",
       "      <th>ager</th>\n",
       "      <th>agescrn</th>\n",
       "      <th>fmarital</th>\n",
       "      <th>rmarital</th>\n",
       "      <th>educat</th>\n",
       "      <th>hieduc</th>\n",
       "      <th>race</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>hisprace</th>\n",
       "      <th>rcurpreg</th>\n",
       "      <th>pregnum</th>\n",
       "      <th>parity</th>\n",
       "      <th>insuranc</th>\n",
       "      <th>pubassis</th>\n",
       "      <th>poverty</th>\n",
       "      <th>laborfor</th>\n",
       "      <th>religion</th>\n",
       "      <th>metro</th>\n",
       "      <th>brnout</th>\n",
       "      <th>yrstrus</th>\n",
       "      <th>prglngth_i</th>\n",
       "      <th>outcome_i</th>\n",
       "      <th>birthord_i</th>\n",
       "      <th>datend_i</th>\n",
       "      <th>agepreg_i</th>\n",
       "      <th>datecon_i</th>\n",
       "      <th>agecon_i</th>\n",
       "      <th>fmarout5_i</th>\n",
       "      <th>pmarpreg_i</th>\n",
       "      <th>rmarout6_i</th>\n",
       "      <th>fmarcon5_i</th>\n",
       "      <th>learnprg_i</th>\n",
       "      <th>pncarewk_i</th>\n",
       "      <th>paydeliv_i</th>\n",
       "      <th>lbw1_i</th>\n",
       "      <th>bfeedwks_i</th>\n",
       "      <th>maternlv_i</th>\n",
       "      <th>oldwantr_i</th>\n",
       "      <th>oldwantp_i</th>\n",
       "      <th>wantresp_i</th>\n",
       "      <th>wantpart_i</th>\n",
       "      <th>ager_i</th>\n",
       "      <th>fmarital_i</th>\n",
       "      <th>rmarital_i</th>\n",
       "      <th>educat_i</th>\n",
       "      <th>hieduc_i</th>\n",
       "      <th>race_i</th>\n",
       "      <th>hispanic_i</th>\n",
       "      <th>hisprace_i</th>\n",
       "      <th>rcurpreg_i</th>\n",
       "      <th>pregnum_i</th>\n",
       "      <th>parity_i</th>\n",
       "      <th>insuranc_i</th>\n",
       "      <th>pubassis_i</th>\n",
       "      <th>poverty_i</th>\n",
       "      <th>laborfor_i</th>\n",
       "      <th>religion_i</th>\n",
       "      <th>metro_i</th>\n",
       "      <th>basewgt</th>\n",
       "      <th>adj_mod_basewgt</th>\n",
       "      <th>finalwgt</th>\n",
       "      <th>secu_p</th>\n",
       "      <th>sest</th>\n",
       "      <th>cmintvw</th>\n",
       "      <th>totalwgt_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12897</th>\n",
       "      <td>11895</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>26.33</td>\n",
       "      <td>1162</td>\n",
       "      <td>2558</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>855</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2080.150751</td>\n",
       "      <td>4219.809849</td>\n",
       "      <td>5355.360680</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>319</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>23.83</td>\n",
       "      <td>1102</td>\n",
       "      <td>2308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>825</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2335.325769</td>\n",
       "      <td>2523.807843</td>\n",
       "      <td>3202.964533</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>3422</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>31.83</td>\n",
       "      <td>1148</td>\n",
       "      <td>3133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>772</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2971.117712</td>\n",
       "      <td>3163.142722</td>\n",
       "      <td>4841.189937</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10263</th>\n",
       "      <td>9472</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>25.66</td>\n",
       "      <td>1003</td>\n",
       "      <td>2491</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>704</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3958.606729</td>\n",
       "      <td>4336.117255</td>\n",
       "      <td>5290.063051</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>8524</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>993</td>\n",
       "      <td>2366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>709</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13638.702003</td>\n",
       "      <td>14953.803756</td>\n",
       "      <td>24920.513959</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       caseid  pregordr  howpreg_n  howpreg_p  moscurrp  nowprgdk  pregend1  \\\n",
       "12897   11895         4        NaN        NaN       NaN       NaN       5.0   \n",
       "325       319         3        NaN        NaN       NaN       NaN       6.0   \n",
       "3841     3422         3        NaN        NaN       NaN       NaN       5.0   \n",
       "10263    9472         2        NaN        NaN       NaN       NaN       6.0   \n",
       "9258     8524         2        NaN        NaN       NaN       NaN       6.0   \n",
       "\n",
       "       pregend2  nbrnaliv  multbrth  cmotpreg  prgoutcome  cmprgend  flgdkmo1  \\\n",
       "12897       NaN       1.0       NaN       NaN         1.0    1171.0       NaN   \n",
       "325         NaN       1.0       NaN       NaN         1.0    1111.0       NaN   \n",
       "3841        NaN       1.0       NaN       NaN         1.0    1154.0       NaN   \n",
       "10263       NaN       1.0       NaN       NaN         1.0    1012.0       NaN   \n",
       "9258        NaN       1.0       NaN       NaN         1.0    1003.0       NaN   \n",
       "\n",
       "       cmprgbeg  ageatend  hpageend  gestasun_m  gestasun_w  wksgest  mosgest  \\\n",
       "12897    1162.0       NaN       NaN         9.0         2.0     41.0      9.0   \n",
       "325      1102.0       NaN       NaN         9.0         0.0     39.0      9.0   \n",
       "3841     1148.0       NaN       NaN         0.0        26.0     26.0      6.0   \n",
       "10263    1003.0       NaN       NaN         9.0         0.0     39.0      9.0   \n",
       "9258      993.0       NaN       NaN         0.0        42.0     42.0     10.0   \n",
       "\n",
       "       dk1gest  dk2gest  dk3gest  bpa_bdscheck1  bpa_bdscheck2  bpa_bdscheck3  \\\n",
       "12897      NaN      NaN      NaN            0.0            NaN            NaN   \n",
       "325        NaN      NaN      NaN            0.0            NaN            NaN   \n",
       "3841       NaN      NaN      NaN            0.0            NaN            NaN   \n",
       "10263      NaN      NaN      NaN            0.0            NaN            NaN   \n",
       "9258       NaN      NaN      NaN            0.0            NaN            NaN   \n",
       "\n",
       "       babysex  birthwgt_lb  birthwgt_oz  lobthwgt  babysex2  birthwgt_lb2  \\\n",
       "12897      2.0          7.0         14.0       NaN       NaN           NaN   \n",
       "325        1.0          7.0         11.0       NaN       NaN           NaN   \n",
       "3841       2.0          1.0          4.0       NaN       NaN           NaN   \n",
       "10263      2.0          6.0         14.0       NaN       NaN           NaN   \n",
       "9258       1.0          7.0         12.0       NaN       NaN           NaN   \n",
       "\n",
       "       birthwgt_oz2  lobthwgt2  babysex3  birthwgt_lb3  birthwgt_oz3  \\\n",
       "12897           NaN        NaN       NaN           NaN           NaN   \n",
       "325             NaN        NaN       NaN           NaN           NaN   \n",
       "3841            NaN        NaN       NaN           NaN           NaN   \n",
       "10263           NaN        NaN       NaN           NaN           NaN   \n",
       "9258            NaN        NaN       NaN           NaN           NaN   \n",
       "\n",
       "       lobthwgt3  cmbabdob  kidage  hpagelb  birthplc  paybirth1  paybirth2  \\\n",
       "12897        NaN    1171.0    66.0     29.0       1.0        3.0        NaN   \n",
       "325          NaN    1111.0   122.0     35.0       NaN        NaN        NaN   \n",
       "3841         NaN    1154.0    78.0     32.0       NaN        NaN        NaN   \n",
       "10263        NaN    1012.0   219.0     25.0       NaN        NaN        NaN   \n",
       "9258         NaN    1003.0   232.0     26.0       NaN        NaN        NaN   \n",
       "\n",
       "       paybirth3  knewpreg  trimestr  ltrimest  priorsmk  postsmks  npostsmk  \\\n",
       "12897        NaN      12.0       NaN       NaN       2.0       5.0       NaN   \n",
       "325          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3841         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "10263        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "9258         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       getprena  bgnprena  pnctrim  lpnctri  workpreg  workborn  didwork  \\\n",
       "12897       1.0      12.0      NaN      NaN       5.0       NaN      NaN   \n",
       "325         NaN       NaN      NaN      NaN       NaN       NaN      NaN   \n",
       "3841        NaN       NaN      NaN      NaN       NaN       NaN      NaN   \n",
       "10263       NaN       NaN      NaN      NaN       NaN       NaN      NaN   \n",
       "9258        NaN       NaN      NaN      NaN       NaN       NaN      NaN   \n",
       "\n",
       "       matweeks  weeksdk  matleave  matchfound  livehere  alivenow  cmkidied  \\\n",
       "12897       NaN      NaN       NaN         1.0       NaN       NaN       NaN   \n",
       "325         NaN      NaN       NaN         5.0       5.0       1.0       NaN   \n",
       "3841        NaN      NaN       NaN         5.0       1.0       NaN       NaN   \n",
       "10263       NaN      NaN       NaN         5.0       1.0       NaN       NaN   \n",
       "9258        NaN      NaN       NaN         NaN       NaN       NaN       NaN   \n",
       "\n",
       "       cmkidlft  lastage  wherenow  legagree  parenend  anynurse  fedsolid  \\\n",
       "12897       NaN      NaN       NaN       NaN       NaN       5.0       NaN   \n",
       "325      1205.0     94.0       1.0       5.0       1.0       5.0       NaN   \n",
       "3841        NaN      NaN       NaN       NaN       NaN       5.0       NaN   \n",
       "10263       NaN      NaN       NaN       NaN       NaN       1.0       NaN   \n",
       "9258        NaN      NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       frsteatd_n  frsteatd_p  frsteatd  quitnurs  ageqtnur_n  ageqtnur_p  \\\n",
       "12897         NaN         NaN       NaN       NaN         NaN         NaN   \n",
       "325           NaN         NaN       NaN       NaN         NaN         NaN   \n",
       "3841          NaN         NaN       NaN       NaN         NaN         NaN   \n",
       "10263         1.0         1.0       1.0       NaN         1.0         1.0   \n",
       "9258          NaN         NaN       NaN       NaN         NaN         NaN   \n",
       "\n",
       "       ageqtnur  matchfound2  livehere2  alivenow2  cmkidied2  cmkidlft2  \\\n",
       "12897       NaN          NaN        NaN        NaN        NaN        NaN   \n",
       "325         NaN          NaN        NaN        NaN        NaN        NaN   \n",
       "3841        NaN          NaN        NaN        NaN        NaN        NaN   \n",
       "10263       1.0          NaN        NaN        NaN        NaN        NaN   \n",
       "9258        NaN          NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "       lastage2  wherenow2  legagree2  parenend2  anynurse2  fedsolid2  \\\n",
       "12897       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "325         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3841        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "10263       NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "9258        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "       frsteatd_n2  frsteatd_p2  frsteatd2  quitnurs2  ageqtnur_n2  \\\n",
       "12897          NaN          NaN        NaN        NaN          NaN   \n",
       "325            NaN          NaN        NaN        NaN          NaN   \n",
       "3841           NaN          NaN        NaN        NaN          NaN   \n",
       "10263          NaN          NaN        NaN        NaN          NaN   \n",
       "9258           NaN          NaN        NaN        NaN          NaN   \n",
       "\n",
       "       ageqtnur_p2  ageqtnur2  matchfound3  livehere3  alivenow3  cmkidied3  \\\n",
       "12897          NaN        NaN          NaN        NaN        NaN        NaN   \n",
       "325            NaN        NaN          NaN        NaN        NaN        NaN   \n",
       "3841           NaN        NaN          NaN        NaN        NaN        NaN   \n",
       "10263          NaN        NaN          NaN        NaN        NaN        NaN   \n",
       "9258           NaN        NaN          NaN        NaN        NaN        NaN   \n",
       "\n",
       "       cmkidlft3  lastage3  wherenow3  legagree3  parenend3  anynurse3  \\\n",
       "12897        NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "325          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "3841         NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "10263        NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "9258         NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "       fedsolid3  frsteatd_n3  frsteatd_p3  frsteatd3  quitnurs3  ageqtnur_n3  \\\n",
       "12897        NaN          NaN          NaN        NaN        NaN          NaN   \n",
       "325          NaN          NaN          NaN        NaN        NaN          NaN   \n",
       "3841         NaN          NaN          NaN        NaN        NaN          NaN   \n",
       "10263        NaN          NaN          NaN        NaN        NaN          NaN   \n",
       "9258         NaN          NaN          NaN        NaN        NaN          NaN   \n",
       "\n",
       "       ageqtnur_p3  ageqtnur3  cmlastlb  cmfstprg  cmlstprg  cmintstr  \\\n",
       "12897          NaN        NaN    1171.0    1050.0    1171.0    1111.0   \n",
       "325            NaN        NaN    1135.0    1034.0    1135.0    1095.0   \n",
       "3841           NaN        NaN    1154.0    1069.0    1201.0    1098.0   \n",
       "10263          NaN        NaN    1012.0     941.0    1012.0     941.0   \n",
       "9258           NaN        NaN    1090.0     976.0    1090.0     976.0   \n",
       "\n",
       "       cmintfin  cmintstrop  cmintfinop  cmintstrcr  cmintfincr  evuseint  \\\n",
       "12897    1171.0      1171.0      1237.0         NaN         NaN       1.0   \n",
       "325      1111.0         NaN         NaN         NaN         NaN       5.0   \n",
       "3841     1154.0         NaN         NaN         NaN         NaN       1.0   \n",
       "10263    1012.0      1012.0      1231.0         NaN         NaN       5.0   \n",
       "9258     1003.0         NaN         NaN         NaN         NaN       1.0   \n",
       "\n",
       "       stopduse  whystopd  whatmeth01  whatmeth02  whatmeth03  whatmeth04  \\\n",
       "12897       5.0       NaN         3.0         NaN         NaN         NaN   \n",
       "325         NaN       NaN         NaN         NaN         NaN         NaN   \n",
       "3841        1.0       1.0         NaN         NaN         NaN         NaN   \n",
       "10263       NaN       NaN         NaN         NaN         NaN         NaN   \n",
       "9258        1.0       1.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "       resnouse  wantbold  probbabe  cnfrmno  wantbld2  timingok  toosoon_n  \\\n",
       "12897       NaN       5.0       NaN      NaN       NaN       NaN        NaN   \n",
       "325         5.0       5.0       NaN      NaN       NaN       NaN        NaN   \n",
       "3841        NaN       NaN       NaN      NaN       NaN       2.0        NaN   \n",
       "10263       5.0       5.0       NaN      NaN       NaN       NaN        NaN   \n",
       "9258        NaN       NaN       NaN      NaN       NaN       2.0        NaN   \n",
       "\n",
       "       toosoon_p  wthpart1  wthpart2  feelinpg  hpwnold  timokhp  cohpbeg  \\\n",
       "12897        NaN       NaN       1.0       NaN        1      4.0      1.0   \n",
       "325          NaN       NaN       2.0       NaN        1      3.0      1.0   \n",
       "3841         NaN       1.0       NaN       NaN        1      2.0      NaN   \n",
       "10263        NaN       NaN       4.0       NaN        1      3.0      1.0   \n",
       "9258         NaN       1.0       NaN       NaN        1      2.0      NaN   \n",
       "\n",
       "       cohpend  tellfath  whentell  tryscale  wantscal  whyprg1  whyprg2  \\\n",
       "12897      1.0       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "325        1.0       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "3841       NaN       1.0       1.0       NaN       NaN      NaN      NaN   \n",
       "10263      1.0       NaN       NaN       NaN       NaN      NaN      NaN   \n",
       "9258       NaN       1.0       1.0       NaN       NaN      NaN      NaN   \n",
       "\n",
       "       whynouse1  whynouse2  whynouse3  anyusint  prglngth  outcome  birthord  \\\n",
       "12897        NaN        NaN        NaN         5        41        1       3.0   \n",
       "325          NaN        NaN        NaN         5        39        1       3.0   \n",
       "3841         NaN        NaN        NaN         5        26        1       2.0   \n",
       "10263        NaN        NaN        NaN         5        39        1       2.0   \n",
       "9258         NaN        NaN        NaN         5        42        1       2.0   \n",
       "\n",
       "       datend  agepreg  datecon  agecon  fmarout5  pmarpreg  rmarout6  \\\n",
       "12897  1171.0    26.33     1162    2558       5.0       1.0       5.0   \n",
       "325    1111.0    23.83     1102    2308       1.0       2.0       1.0   \n",
       "3841   1154.0    31.83     1148    3133       1.0       2.0       1.0   \n",
       "10263  1012.0    25.66     1003    2491       5.0       1.0       5.0   \n",
       "9258   1003.0    24.50      993    2366       1.0       2.0       1.0   \n",
       "\n",
       "       fmarcon5  learnprg  pncarewk  paydeliv  lbw1  bfeedwks  maternlv  \\\n",
       "12897         5      12.0      12.0       4.0   2.0     995.0       0.0   \n",
       "325           5       NaN       NaN       NaN   2.0     995.0       NaN   \n",
       "3841          1       NaN       NaN       NaN   1.0     995.0       NaN   \n",
       "10263         5       NaN       NaN       NaN   2.0       4.0       NaN   \n",
       "9258          1       NaN       NaN       NaN   2.0       NaN       NaN   \n",
       "\n",
       "       oldwantr  oldwantp  wantresp  wantpart  cmbirth  ager  agescrn  \\\n",
       "12897         5         4         5         4      855    31       31   \n",
       "325           5         1         5         1      825    34       34   \n",
       "3841          2         2         2         2      772    38       38   \n",
       "10263         5         1         5         1      704    43       43   \n",
       "9258          2         2         2         2      709    43       43   \n",
       "\n",
       "       fmarital  rmarital  educat  hieduc  race  hispanic  hisprace  rcurpreg  \\\n",
       "12897         5         2       9       5     2         1         1         2   \n",
       "325           4         5      12       9     2         1         1         2   \n",
       "3841          1         1      12       9     1         2         3         2   \n",
       "10263         5         6      12       9     1         2         3         2   \n",
       "9258          1         1      16      12     2         2         2         2   \n",
       "\n",
       "       pregnum  parity  insuranc  pubassis  poverty  laborfor  religion  \\\n",
       "12897        4       3         3         1       54         3         3   \n",
       "325          4       4         1         1      100         2         3   \n",
       "3841         4       2         4         1      128         3         3   \n",
       "10263        2       2         2         2      127         1         3   \n",
       "9258         5       4         2         2      324         7         3   \n",
       "\n",
       "       metro  brnout  yrstrus  prglngth_i  outcome_i  birthord_i  datend_i  \\\n",
       "12897      1       5      NaN           0          0           0         0   \n",
       "325        2       5      NaN           0          0           0         0   \n",
       "3841       1       5      NaN           0          0           0         0   \n",
       "10263      1       5      NaN           0          0           0         0   \n",
       "9258       3       5      NaN           0          0           0         0   \n",
       "\n",
       "       agepreg_i  datecon_i  agecon_i  fmarout5_i  pmarpreg_i  rmarout6_i  \\\n",
       "12897          0          0         0           0           0           0   \n",
       "325            0          0         0           0           0           0   \n",
       "3841           0          0         0           0           0           0   \n",
       "10263          0          0         0           0           0           0   \n",
       "9258           0          0         0           0           0           0   \n",
       "\n",
       "       fmarcon5_i  learnprg_i  pncarewk_i  paydeliv_i  lbw1_i  bfeedwks_i  \\\n",
       "12897           0           0           0           0       0           0   \n",
       "325             0           0           0           0       0           0   \n",
       "3841            0           0           0           0       0           0   \n",
       "10263           0           0           0           0       0           0   \n",
       "9258            0           0           0           0       0           0   \n",
       "\n",
       "       maternlv_i  oldwantr_i  oldwantp_i  wantresp_i  wantpart_i  ager_i  \\\n",
       "12897           0           0           0           0           0       0   \n",
       "325             0           0           0           0           0       0   \n",
       "3841            0           0           0           0           0       0   \n",
       "10263           0           0           0           0           0       0   \n",
       "9258            0           0           0           0           0       0   \n",
       "\n",
       "       fmarital_i  rmarital_i  educat_i  hieduc_i  race_i  hispanic_i  \\\n",
       "12897           0           0         0         0       0           0   \n",
       "325             0           0         0         0       0           0   \n",
       "3841            0           0         0         0       0           0   \n",
       "10263           0           0         0         0       0           0   \n",
       "9258            0           0         0         0       0           0   \n",
       "\n",
       "       hisprace_i  rcurpreg_i  pregnum_i  parity_i  insuranc_i  pubassis_i  \\\n",
       "12897           0           0          0         0           0           0   \n",
       "325             0           0          0         0           0           0   \n",
       "3841            0           0          0         0           0           0   \n",
       "10263           0           0          0         0           0           0   \n",
       "9258            0           0          0         0           0           0   \n",
       "\n",
       "       poverty_i  laborfor_i  religion_i  metro_i       basewgt  \\\n",
       "12897          0           0           0        0   2080.150751   \n",
       "325            0           0           0        0   2335.325769   \n",
       "3841           0           0           0        0   2971.117712   \n",
       "10263          0           0           0        0   3958.606729   \n",
       "9258           0           0           0        0  13638.702003   \n",
       "\n",
       "       adj_mod_basewgt      finalwgt  secu_p  sest  cmintvw  totalwgt_lb  \n",
       "12897      4219.809849   5355.360680       2    78      NaN       7.8750  \n",
       "325        2523.807843   3202.964533       2    55      NaN       7.6875  \n",
       "3841       3163.142722   4841.189937       1    31      NaN       1.2500  \n",
       "10263      4336.117255   5290.063051       1     9      NaN       6.8750  \n",
       "9258      14953.803756  24920.513959       2    23      NaN       7.7500  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "others.sample(len(firsts), replace=True).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregnancy_length():\n",
    "    resultado = np.mean(others.sample(len(firsts), replace=True)['prglngth'])\n",
    "    #test statistic la duración media de las pregnancy\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.60910944935418"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregnancy_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_preg = []\n",
    "for _ in range(1000):\n",
    "    resultado_preg.append(pregnancy_length())\n",
    "    '''compare with mean of firsts'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.60095173351461"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(firsts['prglngth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pvalue  2.5 %\n"
     ]
    }
   ],
   "source": [
    "'''Pvalue'''\n",
    "longer_pregs = 0\n",
    "for x in resultado_preg:\n",
    "    if x>=np.mean(firsts['prglngth']):\n",
    "        longer_pregs += 1\n",
    "print('Pvalue ',longer_pregs/len(resultado_preg)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2.5% of the times is the pregnancy length of others greater or equal than firsts.\n",
    "\n",
    "We reject the null hypothesis.\n",
    "\n",
    "Since the Pvalue is under 5%, we can say that the difference is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19624231086468313"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "dt0FyU4P1MDQ",
    "outputId": "c2ea1f35-9de2-4a7f-ddf4-c8f5b6454887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07803726677754952"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "oHaI5cx41MDU",
    "outputId": "2660e2a5-00f4-46af-953b-225878fcd55f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.167"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "0YI38OWB1MDX"
   },
   "source": [
    "`MakeFrames` reads the NSFG data and returns DataFrames representing all live births, first babies, and others. We extract pregnancy lengths as NumPy arrays, pass them as data to `DiffMeansPermute`, and compute the p-value. The result is about 0.17, which means that we expect to see a difference as big as the observed effect about 17% of the time. So this effect is not statistically significant.\n",
    "\n",
    "`HypothesisTest` provides `PlotCdf`, which plots the distribution of the test statistic and a gray line indicating the observed effect size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "wGzopFJg1MDY"
   },
   "outputs": [],
   "source": [
    "from Resources.Think_Stats.Thinkstats2 import thinkplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LXsmdsDm1MDb",
    "outputId": "6f576aea-fbe1-45d4-ea45-68a1f392e87b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ht.PlotCdf()\n",
    "thinkplot.Show(xlabel='test statistic',\n",
    "ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "btrENvgf1MDf"
   },
   "source": [
    "Repeat the analysis comparing weight of babies between first babies and others, interpret the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "65bZuzOm1MDg"
   },
   "outputs": [],
   "source": [
    "firsts_wtg = firsts.birthwgt_lb.dropna()\n",
    "others_wtg = others.birthwgt_lb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "4SHYqVVB1MDj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data = firsts_wtg.values, others_wtg.values\n",
    "ht = DiffMeansPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10920813530891849"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1528567934022922"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ht.PlotCdf()\n",
    "thinkplot.Show(xlabel='test statistic',\n",
    "ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "AT4Elqbl1MDm"
   },
   "source": [
    "If we run the same analysis with birth weight, the computed p-value is 0; after 1000 attempts, the simulation never yields an effect as big as the observed difference, 0.12 lbs. So we would report p < 0.001, and conclude that the difference in birth weight is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "gq2kajGl1MDn"
   },
   "source": [
    "## Other test statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "s3rOOMOO1MDp"
   },
   "source": [
    "Choosing the best test statistic depends on what question you are trying to address. For example, if the relevant question is whether pregnancy lengths are different for first babies, then it makes sense to test the absolute difference in means, as we did in the previous section.\n",
    "\n",
    "If we had some reason to think that first babies are likely to be late, then we would not take the absolute value of the difference; instead we would use this test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "hJHyie4y1MDr"
   },
   "outputs": [],
   "source": [
    "class DiffMeansOneSided(DiffMeansPermute):\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = group1.mean() - group2.mean()\n",
    "        return test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DiffMeansOneSided` inherits `MakeModel` and `RunModel` from `DiffMeansPermute`; the only difference is that `TestStatistic` does not take the absolute value of the difference. This kind of test is called **one-sided** because it only counts one side of the distribution of differences. The previous test, using both sides, is **two-sided**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = firsts.prglngth.values, others.prglngth.values\n",
    "ht = DiffMeansOneSided(data)\n",
    "pvalue = ht.PValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.093"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "dt0FyU4P1MDQ",
    "outputId": "c2ea1f35-9de2-4a7f-ddf4-c8f5b6454887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07803726677754952"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Ei0Ah2IY1MDv"
   },
   "source": [
    "For this version of the test, the p-value is 0.09. In general the p-value for a one-sided test is about half the p-value for a two-sided test, depending on the shape of the distribution.\n",
    "\n",
    "The one-sided hypothesis, that first babies are born late, is more specific than the two-sided hypothesis, so the p-value is smaller. But even for the stronger hypothesis, the difference is not statistically significant.\n",
    "\n",
    "We can use the same framework to test for a difference in standard deviation. In Section 3.3, we saw some evidence that first babies are more likely to be early or late, and less likely to be on time. So we might hypothesize that the standard deviation is higher. Here’s how we can test that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "K07k8qcu1MDw"
   },
   "outputs": [],
   "source": [
    "class DiffStdPermute(DiffMeansPermute):\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = group1.std() - group2.std()\n",
    "        return test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "DBA5az1S1MDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.082"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = DiffStdPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "PHbqcotY1MD2"
   },
   "source": [
    "This is a one-sided test because the hypothesis is that the standard deviation for first babies is higher, not just different. The p-value is 0.09, which is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "oGuOt7RM1MD3"
   },
   "source": [
    "## Testing a correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "WpN0614A1MD6"
   },
   "source": [
    "This framework can also test correlations. For example, in the NSFG data set, the correlation between birth weight and mother’s age is about 0.07. It seems like older mothers have heavier babies. But could this effect be due to\n",
    "chance?\n",
    "\n",
    "For the test statistic, I use Pearson’s correlation, but Spearman’s would work as well. If we had reason to expect positive correlation, we would do a one-sided test. But since we have no such reason, I’ll do a two-sided test using the absolute value of correlation.\n",
    "\n",
    "The null hypothesis is that there is no correlation between mother’s age and birth weight. By shuffling the observed values, we can simulate a world where the distributions of age and birth weight are the same, but where the variables are unrelated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "VUQADffn1MD7"
   },
   "outputs": [],
   "source": [
    "class CorrelationPermute(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        xs, ys = data\n",
    "        test_stat = abs(thinkstats2.Corr(xs, ys))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        xs, ys = self.data\n",
    "        xs = np.random.permutation(xs)\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "A6yEI8WB1MD_"
   },
   "source": [
    "`data` is a pair of sequences. `TestStatistic` computes the absolute value of Pearson’s correlation. `RunModel` shuffles the xs and returns simulated data.\n",
    "\n",
    "Here’s the code that reads the data and runs the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "YQ5xodmT1MEA"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x5/c_gzdbcx3cq5rrz54srqf47c0000gn/T/ipykernel_60398/3702849690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magepreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalwgt_lb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrelationPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/Belgrave_Topics/Belgrave Valley/Notebooks/Resources/Think_Stats/Thinkstats2/thinkstats2.py\u001b[0m in \u001b[0;36mPValue\u001b[0;34m(self, iters)\u001b[0m\n\u001b[1;32m   2788\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \"\"\"\n\u001b[0;32m-> 2790\u001b[0;31m         self.test_stats = [self.TestStatistic(self.RunModel()) \n\u001b[0m\u001b[1;32m   2791\u001b[0m                            for _ in range(iters)]\n\u001b[1;32m   2792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/Belgrave_Topics/Belgrave Valley/Notebooks/Resources/Think_Stats/Thinkstats2/thinkstats2.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2788\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \"\"\"\n\u001b[0;32m-> 2790\u001b[0;31m         self.test_stats = [self.TestStatistic(self.RunModel()) \n\u001b[0m\u001b[1;32m   2791\u001b[0m                            for _ in range(iters)]\n\u001b[1;32m   2792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/x5/c_gzdbcx3cq5rrz54srqf47c0000gn/T/ipykernel_60398/1606322696.py\u001b[0m in \u001b[0;36mTestStatistic\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTestStatistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtest_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthinkstats2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_stat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/Belgrave_Topics/Belgrave Valley/Notebooks/Resources/Think_Stats/Thinkstats2/thinkstats2.py\u001b[0m in \u001b[0;36mCorr\u001b[0;34m(xs, ys)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m     \u001b[0mmeanx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m     \u001b[0mmeany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/Belgrave_Topics/Belgrave Valley/Notebooks/Resources/Think_Stats/Thinkstats2/thinkstats2.py\u001b[0m in \u001b[0;36mMeanVar\u001b[0;34m(xs, ddof)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \"\"\"\n\u001b[1;32m   2277\u001b[0m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         ret = um.true_divide(\n\u001b[1;32m    182\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "live, firsts, others = first.MakeFrames()\n",
    "live = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "data = live.agepreg.values, live.totalwgt_lb.values\n",
    "ht = CorrelationPermute(data)\n",
    "pvalue = ht.PValue(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "AK3bRo6L1MEE",
    "outputId": "816af1c0-0762-44ca-ca8b-2cba0809ab56"
   },
   "outputs": [],
   "source": [
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "HrBipt4K1MEI"
   },
   "outputs": [],
   "source": [
    "ht.actual, ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thinkstats2.Corr(live.birthwgt_lb, live.pregordr))\n",
    "data = live.birthwgt_lb.values, live.pregordr.values\n",
    "ht = CorrelationPermute(data)\n",
    "pvalue = ht.PValue()\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4k3qboIj1MEL"
   },
   "source": [
    "I use dropna with the subset argument to drop rows that are missing either of the variables we need.\n",
    "\n",
    "The actual correlation is 0.07. The computed p-value is 0; after 1000 iterations the largest simulated correlation is 0.04. So although the observed correlation is small, it is statistically significant.\n",
    "\n",
    "This example is a reminder that “statistically significant” does not always mean that an effect is important, or significant in practice. It only means that it is unlikely to have occurred by chance.\n",
    "\n",
    "Calculate the correlation between weight and height and its p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6lbkPRxj1MEM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "xvj9sjDG1MEQ"
   },
   "source": [
    "## Testing proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "uJCv00RD1MER"
   },
   "source": [
    "Suppose you run a casino and you suspect that a customer is using a crooked die; that is, one that has been modified to make one of the faces more likely than the others. You apprehend the alleged cheater and confiscate the dice but now you have to prove that it is crooked. You roll the die 60 times and get the following results:\n",
    "\n",
    "\n",
    "![alt text](Resources/Think_Stats/notebookpics/dice.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "YYhGb4AE1MET"
   },
   "source": [
    "On average you expect each value to appear 10 times. In this dataset, the value 3 appears more often than expected, and the value 4 appears less often. But are these differences statistically significant?\n",
    "\n",
    "To test this hypothesis, we can compute the expected frequency for each value, the difference between the expected and observed frequencies, and the total absolute difference. In this example, we expect each side to come up 10 times out of 60; the deviations from this expectation are -2, -1, 9, -5, -2, and 1; so the total absolute difference is 20. How often would we see such a difference by chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "sj54khwY1MET"
   },
   "outputs": [],
   "source": [
    "class TestingProportions(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        d_1, d_2, d_3, d_4, d_5, d_6 = data\n",
    "        freq_esperada = sum(data)/6\n",
    "        test_stat = abs(d_1-freq_esperada)+abs(d_2-freq_esperada)+abs(d_3-freq_esperada)+abs(d_4-freq_esperada) \\\n",
    "        +abs(d_5-freq_esperada)+abs(d_6-freq_esperada)\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        d_1, d_2, d_3, d_4, d_5, d_6 = self.data\n",
    "        n = sum(self.data)\n",
    "        sample = [random.choice('123456') for _ in range(n)]\n",
    "        hist = thinkstats2.Hist(sample)\n",
    "        data = hist['1'], hist['2'], hist['3'], hist['4'], hist['5'], hist['6']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (8,9,19,5,8,11)\n",
    "ht = TestingProportions(data)\n",
    "pvalue = ht.PValue(1000)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "MqG1QGvX1MEW"
   },
   "source": [
    "## Chi-squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "S9GL2j7u1MEW"
   },
   "source": [
    "In the previous section we used total deviation as the test statistic. But for testing proportions it is more common to use the **chi-squared statistic**:\n",
    "\n",
    "![alt text](Resources/Think_Stats/notebookpics/chi_squared.png \"Title\")\n",
    "\n",
    "Where O i are the observed frequencies and E i are the expected frequencies. code it in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "_MzqlGZO1MEX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Wy0Rpq-N1MEZ"
   },
   "source": [
    "Squaring the deviations (rather than taking absolute values) gives more weight to large deviations. Dividing through by expected standardizes the deviations, although in this case it has no effect because the expected frequencies are all equal.\n",
    "\n",
    "Repeat the previous example with a Chi-squared test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "BREc6jkh1MEb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "LiGEDWUg1MEd"
   },
   "source": [
    "## First babies again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "OpGAGMfc1MEe"
   },
   "source": [
    "Earlier in this chapter we looked at pregnancy lengths for first babies and others, and concluded that the apparent differences in mean and standard deviation are not statistically significant. But in Section 3.3, we saw several\n",
    "apparent differences in the distribution of pregnancy length, especially in the range from 35 to 43 weeks. To see whether those differences are statistically significant, we can use a test based on a chi-squared statistic.\n",
    "\n",
    "The code combines elements from previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "_TFgsr2R1MEe"
   },
   "outputs": [],
   "source": [
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "        \n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4qJkfjbm1MEh"
   },
   "source": [
    "The data are represented as two lists of pregnancy lengths. The null hypothesis is that both samples are drawn from the same distribution. MakeModel models that distribution by pooling the two samples using hstack. Then RunModel generates simulated data by shuffling the pooled sample and splitting it into two parts.\n",
    "\n",
    "MakeModel also defines values, which is the range of weeks we’ll use, and expected_probs, which is the probability of each value in the pooled distribution.\n",
    "\n",
    "Here’s the code that computes the test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "37VljV7F1MEi"
   },
   "outputs": [],
   "source": [
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "    \n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "        \n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        firsts, others = data\n",
    "        stat = self.ChiSquared(firsts) + self.ChiSquared(others)\n",
    "        return stat\n",
    "    \n",
    "    def ChiSquared(self, lengths):\n",
    "        hist = thinkstats2.Hist(lengths)\n",
    "        observed = np.array(hist.Freqs(self.values))\n",
    "        expected = self.expected_probs * len(lengths)\n",
    "        stat = sum((observed - expected)**2 / expected)\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TestStatistic` computes the chi-squared statistic for first babies and others, and adds them.\n",
    "\n",
    "`ChiSquared` takes a sequence of pregnancy lengths, computes its histogram, and computes observed, which is a list of frequencies corresponding to `self.values`. To compute the list of expected frequencies, it multiplies the precomputed probabilities, expected_probs, by the sample size. It returns  the chi-squared statistic, stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = firsts.prglngth.values, others.prglngth.values\n",
    "ht = PregLengthTest(data)\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "HrBipt4K1MEI"
   },
   "outputs": [],
   "source": [
    "ht.actual, ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.PlotCdf()\n",
    "thinkplot.Show(xlabel='test statistic',\n",
    "ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "-M6k6WMB1MEk"
   },
   "source": [
    "For the NSFG data the total chi-squared statistic is 102, which doesn’t mean much by itself. But after 1000 iterations, the largest test statistic generated under the null hypothesis is 32. We conclude that the observed chi-squared statistic is unlikely under the null hypothesis, so the apparent effect is statistically significant.\n",
    "\n",
    "This example demonstrates a limitation of chi-squared tests: they indicate that there is a difference between the two groups, but they don’t say anything specific about what the difference is.\n",
    "\n",
    "Repeat this analysis comparing the weight of babies between first and other babies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "knP68HkD1MEl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "XaewVU_k1MEn"
   },
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "rfNi2Lk-1MEo"
   },
   "source": [
    "In classical hypothesis testing, an effect is considered statistically significant if the p-value is below some threshold, commonly 5%. This procedure raises two questions:\n",
    "\n",
    "- If the effect is actually due to chance, what is the probability that we will wrongly consider it significant? This probability is the **false positive rate**.\n",
    "- If the effect is real, what is the chance that the hypothesis test will fail? This probability is the **false negative rate**.\n",
    "\n",
    "The false positive rate is relatively easy to compute: if the threshold is 5%, the false positive rate is 5%. Here’s why:\n",
    "\n",
    "- If there is no real effect, the null hypothesis is true, so we can compute the distribution of the test statistic by simulating the null hypothesis. Call this distribution CDF T .\n",
    "\n",
    "- Each time we run an experiment, we get a test statistic, t, which is drawn from CDF T . Then we compute a p-value, which is the probability that a random value from CDF T exceeds t, so that’s 1 − CDF T (t).\n",
    "\n",
    "- The p-value is less than 5% if CDF T (t) is greater than 95%; that is, if t exceeds the 95th percentile. And how often does a value chosen from CDF T exceed the 95th percentile? 5% of the time.\n",
    "\n",
    "So if you perform one hypothesis test with a 5% threshold, you expect a false positive 1 time in 20.\n",
    "\n",
    "Demostrate this calculating multiple time a simulation of the rolling coin with a non bias coin:\n",
    "\n",
    "1. Create a model that rolls 100 times a non biased coin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "zUjZ3WAZ1MEp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "agS9r0Mu1MEr"
   },
   "source": [
    "2. Test 1000 times that the coin is non biased with a 95 % confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "k9zAJ-Zr1MEt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "z1dPZyQG1MEv"
   },
   "source": [
    "## Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dpslk1aP1MEx"
   },
   "source": [
    "The false negative rate is harder to compute because it depends on the actual effect size, and normally we don’t know that. One option is to compute a rate conditioned on a hypothetical effect size.\n",
    "\n",
    "For example, if we assume that the observed difference between groups is accurate, we can use the observed samples as a model of the population and run hypothesis tests with simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "AzUAzlVx1MEy"
   },
   "outputs": [],
   "source": [
    "def FalseNegRate(data, num_runs=100):\n",
    "    group1, group2 = data\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        sample1 = thinkstats2.Resample(group1)\n",
    "        sample2 = thinkstats2.Resample(group2)\n",
    "        \n",
    "        ht = DiffMeansPermute((sample1, sample2))\n",
    "        pvalue = ht.PValue(iters=101)\n",
    "        if pvalue > 0.05:\n",
    "            count += 1\n",
    "        \n",
    "    return count / num_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "AGciy55R1ME3"
   },
   "source": [
    "`FalseNegRate` takes data in the form of two sequences, one for each group. Each time through the loop, it simulates an experiment by drawing a random sample from each group and running a hypothesis test. Then it checks the result and counts the number of false negatives.\n",
    "\n",
    "Resample takes a sequence and draws a sample with the same length, with replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "KfyAtDME1ME4"
   },
   "outputs": [],
   "source": [
    "def Resample(xs):\n",
    "    return np.random.choice(xs, len(xs), replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "pLm-ehB71ME6"
   },
   "source": [
    "Apply it to tests pregnancy lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "so25HFOd1ME7",
    "outputId": "e6a98a27-8158-4da5-af67-8cf1ad4133e9"
   },
   "outputs": [],
   "source": [
    "data = firsts.prglngth.values, others.prglngth.values\n",
    "FalseNegRate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "glLKOUuP1ME9"
   },
   "source": [
    "The result is about 70%, which means that if the actual difference in mean pregnancy length is 0.078 weeks, we expect an experiment with this sample size to yield a negative test 70% of the time.\n",
    "\n",
    "This result is often presented the other way around: if the actual difference is 0.078 weeks, we should expect a positive test only 30% of the time. This “correct positive rate” is called the **power** of the test, or sometimes “sensitivity”. It reflects the ability of the test to detect an effect of a given size.\n",
    "\n",
    "In this example, the test had only a 30% chance of yielding a positive result (again, assuming that the difference is 0.078 weeks). As a rule of thumb, a power of 80% is considered acceptable, so we would say that this test was\n",
    "“underpowered.”\n",
    "\n",
    "In general a negative hypothesis test does not imply that there is no difference between the groups; instead it suggests that if there is a difference, it is too small to detect with this sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": "true",
    "heading_collapsed": true,
    "hidden": true,
    "id": "IuIn2mCV1ME-"
   },
   "source": [
    "## Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "cHJ0ODge1ME_"
   },
   "source": [
    "The hypothesis testing process I demonstrated in this chapter is not, strictly speaking, good practice.\n",
    "\n",
    "First, I performed multiple tests. If you run one hypothesis test, the chance of a false positive is about 1 in 20, which might be acceptable. But if you run 20 tests, you should expect at least one false positive, most of the time.\n",
    "\n",
    "Second, I used the same dataset for exploration and testing. If you explore a large dataset, find a surprising effect, and then test whether it is significant, you have a good chance of generating a false positive.\n",
    "\n",
    "To compensate for multiple tests, you can adjust the p-value threshold (see https://en.wikipedia.org/wiki/Holm-Bonferroni_method). Or you can address both problems by partitioning the data, using one set for exploration\n",
    "and the other for testing.\n",
    "\n",
    "In some fields these practices are required or at least encouraged. But it is also common to address these problems implicitly by replicating published results. Typically the first paper to report a new result is considered ex-\n",
    "ploratory. Subsequent papers that replicate the result with new data are considered confirmatory.\n",
    "\n",
    "As it happens, we have an opportunity to replicate the results in this chapter.\n",
    "The first edition of this book is based on Cycle 6 of the NSFG, which was\n",
    "released in 2002. In October 2011, the CDC released additional data based\n",
    "on interviews conducted from 2006–2010. nsfg2.py contains code to read\n",
    "and clean this data. In the new dataset:\n",
    "\n",
    "- The difference in mean pregnancy length is 0.16 weeks and statistically significant with p < 0.001 (compared to 0.078 weeks in the original dataset).\n",
    "- The difference in birth weight is 0.17 pounds with p < 0.001 (compared to 0.12 lbs in the original dataset).\n",
    "- The correlation between birth weight and mother’s age is 0.08 with p < 0.001 (compared to 0.07).\n",
    "- The chi-squared test is statistically significant with p < 0.001 (as it was in the original).\n",
    "\n",
    "In summary, all of the effects that were statistically significant in the original dataset were replicated in the new dataset, and the difference in pregnancy length, which was not significant in the original, is bigger in the new dataset and significant."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n_hYatqV1MCk",
    "gq2kajGl1MDn",
    "oGuOt7RM1MD3",
    "xvj9sjDG1MEQ",
    "MqG1QGvX1MEW",
    "LiGEDWUg1MEd",
    "XaewVU_k1MEn",
    "z1dPZyQG1MEv",
    "IuIn2mCV1ME-"
   ],
   "name": "Day 27.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
